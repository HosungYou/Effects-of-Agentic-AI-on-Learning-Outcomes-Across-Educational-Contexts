# 핵심 구성개념의 조작적 정의 문제: 학술 근거 기반 심층 분석

**문서 유형**: 내부 논의 문서 (Internal Discussion Document)
**작성일**: 2026-02-27
**프로젝트**: Effects of Agentic AI on Learning Outcomes Across Educational Contexts
**목적**: RQ의 핵심 구성개념에 대한 조작적 정의 검토 및 대안 제안

---

## 목차

1. [문제 제기](#1-문제-제기)
2. ["Agentic AI"의 조작적 정의](#2-agentic-ai의-조작적-정의)
3. [인간 감독 수준과 체크포인트](#3-인간-감독-수준과-체크포인트의-조작적-정의)
4. [단일 에이전트 vs 다중 에이전트](#4-단일-에이전트-vs-다중-에이전트-조작적-구분)
5. [종합 고찰 및 제안](#5-종합-고찰-이-메타분석의-근본적-도전과-해결-방향)
6. [참고문헌](#6-참고문헌)

---

## 1. 문제 제기

본 메타분석의 세 가지 핵심 구성개념에 대해 다음 질문이 제기되었다:

1. **"Agentic AI"란 정확히 무엇인가?** 학계에서 합의된 조작적 정의가 존재하는가?
2. **RQ2의 "체크포인트"는 어떻게 명시될 수 있는가?** "완전 자율 교육"이 현실적으로 가능한가?
3. **RQ3의 "단일 vs 다중 에이전트"는 교육 현장에서 어떤 차이가 있으며**, 이를 어떻게 조작적으로 인식할 수 있는가?

**핵심 가설**: 관련 연구는 많이 수행되었지만, 조작적 정의가 확립되지 않아 메타분석적 종합이 어렵다.

이 문서는 학술 문헌의 체계적 검토를 통해 이 가설을 검증하고, 대안을 제안한다.

---

## 2. "Agentic AI"의 조작적 정의

### 2.1 핵심 발견: 합의된 조작적 정의가 없음

"Agentic AI"는 널리 사용되지만 조작적으로 잘 정의되지 않은 구성개념이다. 모든 주요 출처가 이를 명시적 또는 암묵적으로 인정한다.

#### 주요 출처별 정의 비교

| 출처 | 정의 방식 | 한계 |
|---|---|---|
| **OpenAI** (Shavit et al., 2023) | "복잡한 환경에서 제한된 직접 감독 하에 복잡한 목표를 적응적으로 달성하는 정도" | 연속체로 정의 — "agentic"의 경계 불명확 |
| **Anthropic** (2024) | Workflow(사전 정의 코드 경로) vs Agent(LLM이 자체 프로세스 지시) | 실용적 아키텍처 구분이지 측정 기준이 아님 |
| **MIT AI Agent Index** (2025) | 자율성 + 목표 복잡성 + 환경 상호작용 + 범용성; "3회 이상 자율적 도구 호출" | 가장 구체적 시도이나 상업 제품 분류용으로 설계 |
| **Yan et al. (2025) APCP** | Adaptive → Proactive → Co-Learner → Peer 4단계 | 교육 특화 최고 프레임워크이나 아직 개념적 수준; 실증 검증 미완 |
| **Russell & Norvig** (1995/2021) | "환경을 감지하고 행동하는 모든 것" | 이 정의로는 온도조절기도 에이전트에 해당 |
| **Suri et al. (2025)** | AI Agent와 Agentic AI를 구분하려는 시도 | 논문 자체가 "합의 부재"를 해결하기 위해 작성됨 |
| **Bandi et al. (2025)** | 143개 연구 리뷰 후 "보편적으로 합의된 정의는 없다" 결론 | 메타 수준에서 정의적 혼란 확인 |

#### 정의들의 공통 속성 (Family Resemblance)

```
자율성(Autonomy)              ← 거의 모든 정의에 존재
목표 지향성(Goal-directedness) ← 대부분의 정의
도구 사용(Tool use)            ← CS/AI 정의에서 강조
계획 수립(Planning)            ← LLM 시대 정의에서 강조
최소 인간 감독(Min. supervision)← 대부분의 정의
적응성(Adaptability)           ← 교육 정의에서 강조
다중 에이전트 조율              ← 일부 정의에서만
```

> **핵심 문제**: 각 속성이 "얼마나" 있어야 "agentic"인지를 어느 정의도 명시하지 않는다.

### 2.2 현 계획서의 조작적 정의 평가

현재 계획서는 "6가지 자율적 능력 중 하나 이상"을 충족하면 Agentic AI로 분류한다:

| 능력 | 평가 |
|---|---|
| 적응적 반응 (Adaptive Response) | **지나치게 넓음** — 2000년대 ITS 대부분이 해당. 난이도 조절하는 모든 CAI 포함 |
| 선제적 개입 (Proactive Intervention) | 비교적 명확하나, "학습자 요청 없이"의 판단 기준 모호 |
| 자동 평가 (Automated Assessment) | **지나치게 넓음** — 자동 채점 시스템 대부분 포함 |
| 추천 생성 (Recommendation) | 넷플릭스식 추천도 해당되는지 경계 불분명 |
| 대화 관리 (Dialogue Management) | 비교적 명확 |
| 다중 에이전트 조율 | 비교적 명확 |

**결론**: 현재 조작적 정의는 "Agentic AI"가 아니라 사실상 "AI-enhanced Educational Technology 전반"을 포함한다. 적응형 ITS(2000년대), 자동 채점(2010년대), LLM 튜터(2020년대)가 모두 하나의 범주로 묶이는데, 이들의 기술적 메커니즘과 교육적 작동 원리는 근본적으로 다르다.

### 2.3 Yan (2025) APCP 프레임워크에 대한 비판적 검토

APCP 프레임워크가 이 문제를 해결한다고 계획서는 주장하지만:

1. 아직 실증 검증되지 않은 개념적 프레임워크
2. arXiv 프리프린트 (동료 심사 미완료)
3. 코딩 시 4단계 구분의 신뢰도 미확인
4. 교육 현장에서의 적용 사례 없음

### 2.4 제안: 2단계 조작적 정의 전략

| 단계 | 내용 | 근거 |
|---|---|---|
| **넓은 포함** (검색/스크리닝) | 현행 6가지 기준 유지 → 40-80개 연구 확보 | 통계적 검정력 확보 |
| **"Agenticity" 연속 변수 코딩** (분석) | 각 연구를 MIT Index 4차원으로 0-4점 코딩: 자율성, 목표 복잡성, 환경 상호작용, 범용성 | OpenAI의 "연속체" 관점 반영 |

이 전략의 장점:
- 이진 분류("agentic/non-agentic")의 자의성 문제 회피
- "Agenticity" 점수를 연속형 조절변수로 메타회귀 가능
- 점수가 높을수록 효과가 큰지 검증 → 이것 자체가 새로운 기여

```
[그림 1] Agenticity 연속체 모델

    Non-Agentic                                              Highly Agentic
    |----|----|----|----|----|----|----|----|----|----|
    0    1    2    3    4    5    6    7    8    9    10
    |         |              |              |         |
    정적 콘텐츠  적응형 ITS    대화형 튜터   선제적 에이전트  자율 다중
    (배제)     (포함, 점수 낮음) (포함, 중간)  (포함, 높음)   에이전트
                                                        (포함, 최고)

    ← 현행 기준: 1점 이상이면 모두 포함 →
    ← 제안: 포함 후 연속 점수로 메타회귀 →
```

---

## 3. 인간 감독 수준과 체크포인트의 조작적 정의

### 3.1 "체크포인트"의 학술적 정의 상태

**핵심 발견**: "체크포인트"라는 용어는 AIED 문헌에서 표준화된 조작적 정의가 없다. 관련 프레임워크는 존재하지만 교육 메타분석에 직접 적용된 사례는 0건이다.

#### 관련 프레임워크 현황

| 프레임워크 | 내용 | 교육 메타분석 적용 |
|---|---|---|
| **Parasuraman et al. (2000)** | 10단계 자동화: 정보 획득→분석→의사결정→행동 | **미적용** |
| **Molenaar (2022)** | SAE 자율주행 모델의 교육 적용: L0~L5 | **미적용** (개념적 제안만) |
| **EU AI Act Art.14** | HITL / HOTL / HIC 구분 | 교육 연구에서 거의 사용 안됨 |
| **Jia et al. (2024)** | 28개 HITL-AIED 연구의 실체-관계 분석 | 대부분 2-3개 실체만 기술 |
| **Cheng et al. (2026)** | 교사 주도 vs 자기 주도 (이진) | **유일하게 메타분석에 적용** |

#### 기존 메타분석의 감독 관련 코딩 현황

| 메타분석 | 코딩한 것 | 감독 수준 코딩 여부 |
|---|---|---|
| Ma et al. (2014) ITS | "교수 맥락" (4범주) | 감독이 아닌 수업 맥락 |
| Kulik & Fletcher (2016) | ITS 유형, 비교 처치 | 코딩하지 않음 |
| Dai et al. (2024) | 에이전트 역할, AI 기술, 양식 | 코딩하지 않음 |
| Cheng et al. (2026) | 교사 주도 vs 자기 주도 | **이진 수준으로만** |
| Wang et al. (2024) | 적응 소스, 적응 대상 | 코딩하지 않음 |
| Vaccaro et al. (2024) | 인간+AI vs 인간/AI 단독 | 유/무만 |

> **결론**: 등급화된 감독 척도를 코딩한 AI/교육 메타분석 선례가 존재하지 않는다.

### 3.2 "완전 자율 교육"은 현실적인가?

#### 연구 구성개념으로는 존재하나, 교육학적으로 지지되지 않음

실제 존재하는 "교사 없는" AI 시스템:

| 시스템 | 자율적으로 하는 것 | 하지 못하는 것 |
|---|---|---|
| **Duolingo** | 수업, 피드백, 난이도 적응, 발음 평가 | 사회정서적 지원, 교육과정 연계, 동기 위기 대응 |
| **Khan Academy** (자기주도) | 영상, 연습 문제, 숙달 추적 | 설계 의도상 교사 대시보드 병행; 교사 없는 사용은 설계 목적이 아님 |
| **AutoTutor** (Graesser) | 자연어 대화 약 100턴, 완전 자동 튜터링 | 연구 환경용; d = 0.80이나 교사 없이 실제 교실 배치 사례 거의 없음 |

#### 결정적 실증 증거: Bastani et al. (2025, PNAS)

약 1,000명의 고교 수학 학생을 3집단 무선 배정:
- **비제한 ChatGPT** (가드레일 없음, 교사 미개입): 연습 중 48% 향상, **시험에서 17% 하락**
- **교사 설계 가드레일 ChatGPT**: 해로운 효과 없음
- **통제집단**: 기준선

> **이것은 감독 없는 자율 AI 교육이 학습을 적극적으로 손상시킬 수 있다는 직접 증거이다.**

#### 규제적 현실

- **EU AI Act**: 교육은 고위험 영역(Annex III). Art.14에 따라 인간 감독 의무 → 완전 자율 AI 교육은 EU법 위반
- **UNESCO** (2023, 2024): AI는 지원 도구이지 교사 대체가 아니라는 입장 일관

### 3.3 1차 연구들의 교사 역할 보고 실태

보고 품질은 매우 빈약하다:

- **Topali et al. (2025)**: K-12 AIED 논문의 절반이 교수학적 기초 없이, 교사 역할 기술 없이 학습 결과만 보고
- **Jia et al. (2024)**: HITL-AIED 28개 연구 중 대부분이 일방적 관계만 기술
- **Stains & Vickrey (2017)**: 증거 기반 수업의 실행 충실도 연구가 "교수자의 실천 준수를 특성화하지 않는" 경향 확인

> **이것이 의미하는 바**: 감독 수준을 코딩하려 해도, 1차 연구들이 교사가 AI 사용 중 실제로 무엇을 했는지 보고하지 않기 때문에 코딩이 대부분 추론에 의존하게 된다.

### 3.4 체크포인트의 5가지 유형 제안

학술 문헌 종합에 기반한 분류:

```
[그림 2] 체크포인트 유형별 시간적 배치

    ──────────────────── AI-학습자 상호작용 타임라인 ────────────────────
    |                    |                              |                |
    사전배치 게이트      실시간 대시보드                 사후 검토 게이트
    (Type 1)            (Type 2)                        (Type 4)
                             |           |
                        AI 트리거 경보  공동조율 결정점
                        (Type 3)       (Type 5)
```

| 유형 | 정의 | 실제 사례 | 시점 |
|---|---|---|---|
| **Type 1: 사전배치 게이트** | AI 시스템 구성/범위/매개변수를 교사가 사전 승인 | Khanmigo 매개변수 설정; ChatGPT 가드레일 설계 (Bastani et al., 2025) | AI 상호작용 **전** |
| **Type 2: 실시간 대시보드** | 교사가 AI 사용 중 학습자 상태를 실시간 모니터링 | Holstein et al. (2019) Lumilo 스마트 안경 | **동시** |
| **Type 3: AI 트리거 경보** | AI가 특정 조건 감지 시 인간에게 알림 | 조기 경보 시스템; 학생 성적 하락 플래그 | **사건 기반** |
| **Type 4: 사후 검토 게이트** | 교사가 AI 생성 출력을 사후 검토/수정 | Eedi/DeepMind LearnLM 교사 승인 (2025) | AI 상호작용 **후** |
| **Type 5: 공동조율 결정점** | AI가 행동을 제안하고 교사 승인 대기 | Lawrence et al. (2024) Pair-Up 공동조율 도구 | **의사결정 시** |

### 3.5 현 계획서의 3-수준 코딩에 대한 비판

현재 계획서의 3-수준 분류:

```
Level 1: 완전 자율 — AI가 인간 검토 없이 행동
Level 2: AI 주도 + 체크포인트 — 인간이 정의된 간격으로 검토
Level 3: 인간 주도 + AI 지원 — 인간이 주요 통제 유지
```

**문제 1**: Level 1은 "부재 = 자율"로 코딩됨. 계획서의 결정 규칙에 따르면, 감독 메커니즘이 기술되지 않으면 완전 자율로 코딩된다. 이것은 보고 편향을 체계적으로 코딩에 반영한다.

**문제 2**: Level 2의 "정의된 간격"은 대부분의 1차 연구에서 확인 불가능하다. 교사가 언제, 얼마나 자주, 어떤 조건에서 개입하는지 보고되지 않는다.

**문제 3**: Level 2와 Level 3의 경계가 모호하다. "AI 주도 + 체크포인트"와 "인간 주도 + AI 지원"의 차이는 연속체이지 이산적 범주가 아니다.

### 3.6 대안 제안: 계층적 코딩 전략

Cheng et al. (2026)이 이진 코딩(교사 주도 vs 자기 주도)만으로도 유의한 조절 효과를 검출한 점을 고려하여:

| 전략 | 내용 |
|---|---|
| **1차 분석: 이진 코딩** | "교사 관여 있음" vs "교사 관여 없음/미보고" — Cheng et al. (2026) 선례 활용 |
| **2차 분석: 3-수준 (탐색적)** | 코딩 가능한 하위집단에서만 3-수준 적용; k가 충분하면 보고 |
| **미보고 범주 분리** | "미보고"를 "완전 자율"과 별도 범주로 유지하여 보고 편향과 실제 자율을 분리 |

```
[그림 3] 제안된 계층적 코딩 전략

                    전체 연구 풀 (k = 40-80)
                           |
              ┌────────────┴────────────┐
              |                         |
    교사 관여 보고됨              교사 관여 미보고
    (1차 분석: "있음")           (1차 분석: "없음/미보고")
              |                         |
    ┌─────────┼─────────┐         별도 범주로 유지
    |         |         |         ("자율"과 구분)
  Level 3  Level 2   Level 1
  인간주도  AI주도+CP  자율(명시)
  (2차 분석: 탐색적, 충분한 k가 있을 때만)
```

---

## 4. 단일 에이전트 vs 다중 에이전트: 조작적 구분

### 4.1 핵심 발견: 세 가지 서로 다른 정의가 공존

이 구분은 실재하지만, 누가 정의하느냐에 따라 전혀 다른 것을 의미한다.

| 관점 | "다중 에이전트"의 의미 | 기준 |
|---|---|---|
| **컴퓨터 과학** (Wooldridge & Jennings, 1995) | 사적 상태를 가진 2개 이상의 자율적 의사결정 실체가 상호작용 | 아키텍처적: 사적 상태 + 통신 프로토콜 |
| **교육공학** (Lippert/Graesser et al., 2020) | 학습자가 구별 가능한 2개 이상의 캐릭터와 상호작용 | 현상학적: 학습자의 지각 경험 |
| **LLM 시대** (AutoGen, CrewAI) | 다른 시스템 프롬프트/도구를 가진 다중 LLM 호출 | 기능적: 역할 분리 여부 |

### 4.2 세 정의가 완전히 다를 수 있는 사례

```
[그림 4] 세 가지 정의의 괴리

사례 A: 하나의 LLM이 "튜터"와 "동료" 페르소나를 번갈아 연기
┌─────────────────────────────────────────────────┐
│  아키텍처적:  단일 에이전트  ← 하나의 모델      │
│  현상학적:    다중 에이전트  ← 학습자는 2명 인식 │
│  기능적:      다중 역할      ← 두 개의 역할     │
└─────────────────────────────────────────────────┘

사례 B: 5개 LLM이 백엔드에서 교육과정 분해/평가/전략/성찰/기억 처리
┌─────────────────────────────────────────────────┐
│  아키텍처적:  다중 에이전트  ← 5개의 모델       │
│  현상학적:    단일 에이전트  ← 학습자는 1개 인터페이스만 │
│  기능적:      다중 역할      ← 다섯 개의 역할   │
└─────────────────────────────────────────────────┘

사례 C: AutoTutor 삼자대화 (튜터 + 동료 학생 + 인간)
┌─────────────────────────────────────────────────┐
│  아키텍처적:  다중 에이전트  ← 2개의 에이전트   │
│  현상학적:    다중 에이전트  ← 학습자가 2명 인식 │
│  기능적:      다중 역할      ← 두 개의 역할     │
└─────────────────────────────────────────────────┘
```

### 4.3 교육적으로 중요한 것은 무엇인가?

Graesser 연구팀의 핵심 발견: 삼자대화(trialogue)에서 두 에이전트가 의견 불일치를 보이면 **생산적 혼란(productive confusion)**이 유발되어 더 깊은 학습이 발생한다. 이 메커니즘은:

- **인지적 불균형** (cognitive disequilibrium)
- **대리 학습** (vicarious learning — 에이전트 간 대화 관찰)
- **사회적 역할 모델링**

이것은 **현상학적 다중 에이전트**의 효과이다 — 학습자가 여러 캐릭터를 인식하고 그들 간의 사회적 역동을 경험하는 것이 핵심이다.

### 4.4 최근 연구의 결정적 반증

두 편의 2026년 논문이 강력한 증거를 제시:

**"Rethinking the Value of Multi-Agent Workflow" (arXiv, 2026)**
- 7개 벤치마크에서 단일 에이전트가 다중 에이전트와 동일 또는 우수한 성능, 비용 약 23% 절감
- 수학적 증명: 동종(homogeneous) 다중 에이전트 = 단일 에이전트 (도구 부작용이 결정적이고 라우팅이 가시 이력에만 의존할 때)

**"When Single-Agent with Skills Replace Multi-Agent Systems" (arXiv, 2026)**
- 다중 에이전트 오버헤드: 토큰 사용 58%-515% 증가, 클라우드 비용 30-50% 증가
- 진정 필요한 조건: (a) 복잡한 상호의존성, (b) 통합 불가능한 도메인 특화 지식, (c) 병렬 처리 필요, (d) 창발적 합의 필요

### 4.5 실증 연구 현황

직접 비교 연구가 극히 부족하다:

| 범주 | 확인된 연구 수 (k) |
|---|---|
| 다중 에이전트 vs **단일** 에이전트, 학습 결과 | **k = 2** (최대 3) |
| 다중 에이전트 vs **무** 에이전트/전통, 학습 결과 | **k = 7-9** |
| 다중 에이전트 vs **모든** 통제, 학습 결과 | **k ≈ 9-11** |

> **결론**: 단일 vs 다중 에이전트 하위집단 비교는 k >= 4를 충족하지 못한다.

### 4.6 제안: RQ3 재조작화

| 현재 RQ3 | 제안된 대안 |
|---|---|
| "단일 에이전트 vs 다중 에이전트의 효과 차이는?" | **"학습자가 인식하는 에이전트 수(1 vs 2+)가 학습 결과를 조절하는가?"** |

이 재구성의 장점:
1. **현상학적 정의** 채택 → 코딩 신뢰도 대폭 향상
2. 교육적으로 의미 있는 메커니즘(사회적 역동, 대리 학습)에 초점
3. 코딩 가능한 연구 풀 확대 (k = 7-9 가능)
4. 아키텍처 차이와 학습자 경험 차이 구분이 이론적으로 타당

```
[그림 5] 제안된 RQ3 재조작화

현재: 아키텍처 기반 구분
┌─────────────┐     ┌─────────────┐
│ 단일 에이전트 │ vs  │ 다중 에이전트 │  → k = 2-3 (부족)
│ (백엔드 1개) │     │ (백엔드 2+개)│
└─────────────┘     └─────────────┘

제안: 학습자 경험 기반 구분
┌──────────────────┐     ┌──────────────────┐
│ 단일 캐릭터 인식   │ vs  │ 다중 캐릭터 인식   │  → k = 7-9 (가능)
│ (학습자가 1명 봄)  │     │ (학습자가 2+명 봄) │
└──────────────────┘     └──────────────────┘
```

---

## 5. 종합 고찰: 이 메타분석의 근본적 도전과 해결 방향

### 5.1 세 구성개념 공통 문제

| 구성개념 | 학계 정의 상태 | 코딩 실현가능성 |
|---|---|---|
| Agentic AI | 합의 없음 — 연속체이지 범주 아님 | 이진 포함/배제는 가능하나 자의적 |
| 인간 감독 수준 | 프레임워크 존재하나 메타분석 적용 **0건** | 이진은 가능, 3-수준은 위험 |
| 단일/다중 에이전트 | 세 가지 서로 다른 정의 공존 | 현상학적 정의만 신뢰성 있게 코딩 가능 |

> **핵심 진단**: 이것은 **구성개념 타당도(construct validity) 문제**이다. 측정하려는 것이 명확하지 않으면, 아무리 정교한 메타분석을 해도 결과 해석이 모호해진다.

### 5.2 종합 제안: 메타분석 재설계 방향

현 설계를 전면 폐기하는 것이 아니라, 조작화를 현실적으로 조정하는 방향이다.

| 요소 | 현재 | 제안 |
|---|---|---|
| **포함 기준** | "Agentic AI" 이진 분류 | 유지하되, Agenticity 연속 점수 (0-4) 추가 코딩 → 메타회귀 |
| **RQ2 (감독)** | 3-수준 범주 (1차 조절변수) | 1차: 이진 (교사 관여 유/무) + 2차: 3-수준 (탐색적) |
| **RQ3 (아키텍처)** | 단일 vs 다중 에이전트 (1차 조절변수) | 학습자 인식 에이전트 수로 재조작화 + 탐색적으로 격하 |
| **"미보고" 처리** | 부재 = 완전 자율 | "미보고"를 독립 범주로 분리 |
| **이론 기반** | Parasuraman 10→3 축소 | Molenaar (2022) 6단계를 1차 참조로 추가 |

### 5.3 이 재설계의 장점

1. **조작적 정의의 투명성 강화** → 리뷰어 비판 선제 대응
2. **코딩 신뢰도 향상** → 이진 코딩은 3-수준보다 kappa 달성 용이
3. **증거 부족 영역의 솔직한 인정** → 갭으로 프레이밍하면 기여로 전환
4. **"조작적 정의 제안" 자체가 기여** → 현재 문헌에 없는 것을 정리하여 제공

> **핵심 통찰**: 이 메타분석의 가장 큰 기여는 효과 크기 하나가 아니라, "교육 AI의 인간 감독을 어떻게 코딩할 것인가"라는 방법론적 프레임워크를 제안하는 것이 될 수 있다. Parasuraman (2000) → Molenaar (2022) → 본 연구의 교육 메타분석 특화 코딩 체계라는 계보를 세우면, 이것만으로도 독립적 기여이다.

---

## 6. 참고문헌

### Agentic AI 정의

- Bandi, A., et al. (2025). The Rise of Agentic AI: A Review of Definitions, Frameworks, Architectures, Applications, Evaluation Metrics, and Challenges. *Future Internet*, 17(9), 404.
- Huyen, C. (2025). Agents. Blog post, January 2025.
- MIT (2025). The 2025 AI Agent Index. aiagentindex.mit.edu.
- OpenAI / Shavit, Y., et al. (2023). Practices for Governing Agentic AI Systems. OpenAI whitepaper.
- Anthropic (2024). Building Effective Agents. Blog post, December 2024.
- Russell, S. & Norvig, P. (2021). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.
- Suri, M., et al. (2025). AI Agents vs. Agentic AI: A Conceptual Taxonomy. *Information Fusion*.
- Yan, L. (2025). From Passive Tool to Socio-cognitive Teammate: APCP Framework. arXiv:2508.14825.

### 인간 감독 및 자동화 수준

- Bastani, H., et al. (2025). Generative AI without guardrails can harm learning. *PNAS*.
- Cheng, L., et al. (2026). Do GenAI-powered pedagogical agents improve academic performance? *JCER*.
- EU AI Act (2024). Article 14: Human Oversight.
- Holstein, K., et al. (2019). Co-Designing a Real-Time Classroom Orchestration Tool. *Journal of Learning Analytics*, 6(2), 27-52.
- Jia, F., et al. (2024). Human-in-the-loop in AIED: A review and ER analysis. *CEAI*, 6.
- Lawrence, L., et al. (2024). How teachers conceptualise shared control with an AI co-orchestration tool. *BJET*.
- Molenaar, I. (2022). Towards hybrid human-AI learning technologies. *European Journal of Education*, 57(4), 632-645.
- Parasuraman, R., et al. (2000). A model for types and levels of human interaction with automation. *IEEE Trans. SMC*, 30(3), 286-297.
- Topali, P., et al. (2025). Pedagogical considerations in the automation era. *BERJ*.
- UNESCO (2023). Guidance for generative AI in education and research.
- UNESCO (2024). AI Competency Framework for Teachers.

### 단일/다중 에이전트

- Botti, V. (2025). Agentic AI and Multiagentic: Are We Reinventing the Wheel? arXiv:2506.01463.
- Goldberg, Y. (2024). What makes multi-agent LLM systems multi-agent? GitHub Gist.
- Lippert, A., et al. (2020). Multiple Agent Designs in Conversational ITS. *Technology, Knowledge and Learning*, 25, 443-463.
- Rethinking the Value of Multi-Agent Workflow (2026). arXiv:2601.12307.
- When Single-Agent with Skills Replace Multi-Agent Systems (2026). arXiv:2601.04748.
- Wooldridge, M. & Jennings, N.R. (1995). Intelligent Agents: Theory and Practice. *Knowledge Engineering Review*, 10(2), 115-152.

### 메타분석 방법론

- Dai, C.-P., et al. (2024). Effects of AI-Powered Virtual Agents. *Educational Psychology Review*, 36, 31.
- Ma, W., et al. (2014). Intelligent Tutoring Systems and Learning Outcomes. *JEP*, 106(4), 901-918.
- Vaccaro, M., et al. (2024). When combinations of humans and AI are useful. *Nature Human Behaviour*, 8(12), 2293-2303.
- Wang, X., et al. (2024). The efficacy of AI-enabled adaptive learning systems. *JCER*.

---

*본 문서는 내부 논의용이며, 최종 방법론적 결정 전 공저자 검토를 권장한다.*
