# Screening Criteria â€” Trust in Educational AI Scoping Review

## Framework

This scoping review uses the **PCC framework** (Population, Concept, Context) following JBI methodology for scoping reviews (Peters et al., 2020), NOT the PICOS framework used in the parent meta-analysis.

---

## PCC Inclusion Criteria

| Element | Include | Exclude |
|---------|---------|---------|
| **Population** | Learners or educators in formal/informal educational settings (K-12, higher education, adult education, professional development) | Non-educational populations (patients, consumers, general public, workers in non-training contexts) |
| **Concept** | Explicitly discusses trust in AI or related constructs: trust, reliance, resistance, overtrust, distrust, calibration, over-reliance, under-reliance, appropriate reliance | Trust in human teachers/peers only; AI studies without trust discussion; general technology acceptance without trust construct |
| **Context** | AI-based educational tools: intelligent tutoring systems (ITS), AI chatbots, generative AI tools (ChatGPT, Copilot), AI agents, conversational agents, AI writing assistants, AI-powered learning platforms | AI systems outside education (healthcare AI, autonomous vehicles, military AI); non-AI educational technology |

---

## Additional Filters

| Criterion | Include | Exclude |
|-----------|---------|---------|
| **Study type** | Empirical studies (quantitative, qualitative, mixed methods), conceptual papers with explicit framework, systematic/scoping reviews, meta-analyses | Opinion/editorial pieces, conference abstracts without full text, book reviews |
| **Language** | English | Non-English |
| **Date range** | 2015-2026 | Pre-2015 |
| **Publication** | Peer-reviewed journal articles, full conference papers, dissertations | News articles, blog posts, white papers, non-peer-reviewed reports |

---

## Screening Decision Guide

### Title/Abstract Screening

For each record, apply these questions in order:

**Q1: Is trust (or a related construct) mentioned?**
- Look for: trust, reliance, resistance, overtrust, distrust, calibration, trustworthiness, credibility (in AI context), confidence in AI
- If NO mention of trust/reliance/resistance --> EXCLUDE (reason: no trust concept)

**Q2: Is the context educational?**
- Look for: student, learner, teacher, education, classroom, course, university, school, training, instruction, tutoring, learning
- If NO educational context --> EXCLUDE (reason: non-educational context)

**Q3: Does it involve AI technology?**
- Look for: AI, artificial intelligence, intelligent tutoring, chatbot, GPT, LLM, machine learning, automated, conversational agent, recommendation system
- If NO AI involvement --> EXCLUDE (reason: no AI)

**Q4: Is it a substantive study or framework?**
- Accept: empirical data, proposed framework, systematic review, conceptual analysis
- Reject: 1-page editorial, book review, abstract-only
- If just an opinion piece --> EXCLUDE (reason: not substantive)

**If passes Q1-Q4 --> INCLUDE**
**If uncertain on any question --> UNCERTAIN (flag for human review)**

---

## Full-Text Eligibility

At the full-text stage, additionally verify:

| Check | Criterion |
|-------|-----------|
| Full text available? | Must have accessible full text in English |
| Trust is substantively discussed? | Trust/reliance/resistance is a primary variable, not just mentioned in passing |
| Educational AI context confirmed? | The AI system is used for educational purposes (not just studied by education researchers in non-educational contexts) |
| Contains extractable information? | Study provides data or framework elements that can be charted |

---

## Exclusion Reason Codes

For title/abstract screening:

| Code | Reason |
|------|--------|
| E1 | No trust concept discussed |
| E2 | Non-educational context |
| E3 | No AI technology involved |
| E4 | Not substantive (opinion, abstract-only, book review) |
| E5 | Non-English |
| E6 | Pre-2015 |
| E7 | Duplicate |

For full-text screening:

| Code | Reason |
|------|--------|
| F1 | Full text unavailable |
| F2 | Trust only mentioned in passing (not a main construct) |
| F3 | Educational AI context not confirmed on full read |
| F4 | No extractable data or framework elements |
| F5 | Wrong study type (opinion, editorial confirmed) |

---

## Special Cases

### Studies citing Wang et al. (2025), Lee & See (2004), or de Visser et al. (2020)

These are **priority candidates**. Even if the title/abstract is ambiguous, flag as INCLUDE for full-text review. These studies are most likely to contain relevant trust calibration discussions.

### Technology Acceptance Model (TAM) studies

Include if trust is an explicitly measured/discussed variable within the TAM model.
Exclude if trust is only implied through "perceived usefulness" or "perceived ease of use" without explicit trust measurement.

### AI ethics papers discussing "trustworthy AI"

Include if the paper connects trustworthiness to educational use and discusses learner/educator trust.
Exclude if purely technical (algorithmic fairness, explainability) without educational trust perspective.

### Systematic reviews and meta-analyses

Include as information sources. Chart their scope and findings but flag as "review" in study type to distinguish from primary empirical studies.

---

## Inter-Rater Reliability

Since this is a solo-researcher scoping review with AI-assisted screening:
- AI screens all records
- Human verifies all UNCERTAIN records
- Human spot-checks 10% random sample of EXCLUDE decisions
- Human reviews all records citing key seed papers (Wang, Lee & See, de Visser)
- Report AI-human agreement rate in manuscript

---

## PRISMA-ScR Compliance Notes

- All screening decisions will be documented
- Reasons for exclusion at full-text stage will be reported per study
- PRISMA-ScR flow diagram will include all stages
- The use of AI-assisted screening will be transparently reported in the Methods section
