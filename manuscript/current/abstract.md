# Effects of Agentic AI on Learning Outcomes Across Educational Contexts: A Meta-Analysis with Implications for Human-AI Learning Orchestration

## Abstract

### Background

AI systems capable of autonomous pedagogical action are rapidly expanding across educational contexts, yet meta-analytic evidence on a critical design dimension remains absent: how should human oversight be calibrated during AI-assisted learning? Existing meta-analyses have examined intelligent tutoring systems (Ma et al., 2014) and AI virtual agents in simulations (Dai et al., 2024), but none have applied established automation level taxonomies (Parasuraman et al., 2000) to examine human oversight as a moderator of AI effectiveness in education — a gap made pressing by emerging AI governance mandates requiring human oversight of high-risk AI systems, including those deployed in education (EU AI Act, 2024).

### Purpose

This meta-analysis synthesizes empirical evidence on the effects of agentic AI on learning outcomes across K-12, higher education, and workplace training contexts. Five research questions guide the analysis: (1) the overall effect of agentic AI on learning outcomes; (2) the moderating role of human oversight level — fully autonomous, AI-led with human checkpoints, and human-led with AI support — coded using a three-level taxonomy grounded in automation theory; (3) the comparative effectiveness of single-agent versus multi-agent architectures; (4) differential effects across learning contexts; and (5) the derivation of empirically grounded design principles for the HALO (Human-AI Learning Orchestration) Framework.

### Method

Following PRISMA 2020 guidelines, six databases (Web of Science, Scopus, ERIC, PsycINFO, IEEE Xplore, and ACM Digital Library) are searched for experimental and quasi-experimental studies published between 2018 and 2025. Agentic AI is operationally defined as AI systems exhibiting autonomous pedagogical action across the agency spectrum, from adaptive response through peer-level interaction (Yan, 2025). Effect sizes are computed as Hedges' *g* within a random-effects framework (REML estimator), with robust variance estimation (RVE) to handle dependent effect sizes. Moderator analyses employ three-level meta-analytic models with robust inference via cluster-robust variance estimation.

### Expected Contributions

This study introduces human oversight level as a novel moderator in educational AI meta-analysis, drawing on established automation level frameworks (Parasuraman et al., 2000) and responsive to current AI governance requirements (EU AI Act, 2024). Additionally, moderator analysis results are systematically mapped to the HALO (Human-AI Learning Orchestration) Framework — a three-layer evidence-based architecture (Foundation, Protocol, Orchestration) that translates meta-analytic findings into actionable design principles for AI agent-based learning systems across educational contexts.

**Keywords:** agentic AI, meta-analysis, learning outcomes, human oversight, automation levels, multi-agent systems, HALO framework, educational technology
